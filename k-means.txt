import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Load the dataset
data = pd.read_csv(r"Mall_Customers.csv")

# Select relevant features for clustering
features = data[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]

# Handle potential NaN values
features = features.fillna(0)

# Standardize the data
scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)

# Determine the optimal number of clusters using the Elbow method
inertia = []
K = range(2, 21)  # Extend K range for better search

for k in K:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(scaled_features)
    inertia.append(kmeans.inertia_)

# Plot the Elbow method graph for Inertia
plt.figure(figsize=(6, 5))
plt.plot(K, inertia, 'bo-')
plt.xlabel('Number of clusters (K)')
plt.ylabel('Inertia')
plt.title('Elbow Method For Optimal K')
plt.grid()
plt.show()

# Choose the optimal number of clusters (you can pick it visually from the elbow plot)
optimal_k = 5  # Example, update this based on the elbow plot
print(f'Optimal number of clusters (K): {optimal_k}')

kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
data['Cluster'] = kmeans.fit_predict(scaled_features)

# Count the number of instances in each cluster
cluster_counts = data['Cluster'].value_counts()
print(f'Counts of instances per cluster:\n{cluster_counts}')

# Save the results back to a new CSV file with cluster labels
output_path = r"output_file.csv"
data.to_csv(output_path, index=False)
print(f'Clustered data saved to {output_path}')

# Perform PCA for visualization
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
pca_result = pca.fit_transform(scaled_features)

# Scatter plot of clusters
plt.figure(figsize=(10, 6))
plt.scatter(pca_result[:, 0], pca_result[:, 1], c=data['Cluster'], cmap='viridis', s=50)
plt.title(f'Customer Clusters (K={optimal_k}) - PCA Visualization')
plt.xlabel('PCA Component 1 (Age, Income, Spending Score Combined)')
plt.ylabel('PCA Component 2 (Age, Income, Spending Score Combined)')

# Mark the centroids
centroids = pca.transform(kmeans.cluster_centers_)
plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='X', s=200, label='Centroids')
plt.legend()
plt.grid()
plt.show()

